# OSS-Sensor example environment. Copy to .env and set as needed.
# The backend loads .env from the current working directory when running CLI or API.

# -----------------------------------------------------------------------------
# Optional: LLM report enrichment (OpenAI or Anthropic)
# Install LLM support: pip install -e ".[llm]" in the backend directory.
# Then run: oss-sensor report --diff-id 1 --with-llm
# -----------------------------------------------------------------------------

# Provider: "openai" or "anthropic" (leave empty for rules-only, no API calls)
LLM_PROVIDER=

# API key: use one of the following
# - LLM_API_KEY for any provider
# - OPENAI_API_KEY when using OpenAI
# - ANTHROPIC_API_KEY when using Anthropic
LLM_API_KEY=
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...

# Optional: model name (defaults: gpt-4o-mini for OpenAI, claude-3-5-sonnet-20241022 for Anthropic)
# LLM_MODEL=gpt-4o
# LLM_MODEL=claude-3-5-sonnet-20241022

# Optional: request timeout in seconds (default 60)
# LLM_TIMEOUT_SECONDS=90

# -----------------------------------------------------------------------------
# Storage (defaults are usually fine)
# -----------------------------------------------------------------------------
# STORAGE_MODE=derived_features_only
# DATABASE_URL=sqlite+aiosqlite:///./data/oss_sensor.db
